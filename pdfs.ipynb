{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tabula\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "#pd.options.display.max_rows = 2000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change campus names\n",
    "def change_school_name(df):\n",
    "    \n",
    "    # school name dictionary\n",
    "    school_dict = {\n",
    "        '\\t\\r': '',\n",
    "        '-\\xad': '',\n",
    "        'Bilingual': '',\n",
    "        'NON-LEP DL': '',\n",
    "        'Non‐LEP DL': '',\n",
    "        'LEP DL BIL': '',\n",
    "        'ESL': '',\n",
    "        'ESOL': '',\n",
    "        'Regular': '',\n",
    "        'Self Contained': '',\n",
    "        'S C': '',\n",
    "        'Chisholm Trail': 'Chisholm Trail',\n",
    "        'Mt.': 'Mountain',\n",
    "        'Tr.': 'Trail',\n",
    "        \n",
    "        'MIS': '',\n",
    "        'ES': '',\n",
    "        'MS': '',\n",
    "        'HS': '',\n",
    "        'High School': '',\n",
    "        'Elementary School': '',\n",
    "        'Middle School': '',\n",
    "        'Elem School': '',\n",
    "        'Elementary': '',\n",
    "        'Elem: ': '',\n",
    "        'EC': 'Early College',\n",
    "        'Wm S Lott Juvenile Ctr': 'LOTT',\n",
    "        'Wm. Lott': 'LOTT',\n",
    "        'Lott': 'LOTT',\n",
    "        'RROC': 'Round Rock Opportunity Center',\n",
    "        'Daep': 'DAEP',\n",
    "        'Deepwood': 'Deep Wood',\n",
    "        'Liveoak': 'Live Oak',\n",
    "        'Joe Lee': '',\n",
    "        'Xenia': '',\n",
    "        'Patsy': '',\n",
    "        'Neysa': '',\n",
    "        'Noel': '',\n",
    "        'C.D.': 'CD',\n",
    "        'C. D.': 'CD',\n",
    "        'Claude': '',\n",
    "        'Elsa': '',\n",
    "        'James': '',\n",
    "        'Kathy': '',\n",
    "        'Linda': '',\n",
    "        'Patsy': '',\n",
    "        'RRISD': '',\n",
    "        'Non-LEP DL': '',\n",
    "        'Trailil': 'Trail',\n",
    "    }\n",
    "    \n",
    "    # change keys(k) to values(v)\n",
    "    for k, v in school_dict.items():\n",
    "        df['School'] = df['School'].str.replace(k, v).str.strip()\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "school_type = {\n",
    "    # list of middle schools\n",
    "    'CD Fulkes': 'MS',\n",
    "    'Canyon Vista': 'MS',\n",
    "    'Cedar Valley': 'MS',\n",
    "    'Chisholm Trail': 'MS',\n",
    "    'Deerpark': 'MS',\n",
    "    'Grisham': 'MS',\n",
    "    'Hernandez': 'MS',\n",
    "    'Hopewell': 'MS',\n",
    "    'Pearson Ranch': 'MS',\n",
    "    'Ridgeview': 'MS',\n",
    "    'Walsh': 'MS',\n",
    "    \n",
    "    # list of high schools\n",
    "    'Cedar Ridge': 'HS',\n",
    "    'McNeil': 'HS',\n",
    "    'Round Rock': 'HS',\n",
    "    'Stony Point': 'HS',\n",
    "    'Westwood': 'HS',\n",
    "    'Success': 'HS',\n",
    "    'Early College': 'HS',\n",
    "    \n",
    "    # other schools\n",
    "    'Round Rock Opportunity Center': 'Other',\n",
    "    'DAEP': 'Other',\n",
    "    'JJAEP': 'Other',\n",
    "    'LOTT': 'Other',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01-08-13.pdf.pdf\n",
      "01-15-13.pdf.pdf\n",
      "01-22-13.pdf.pdf\n",
      "01-29-13.pdf.pdf\n",
      "02-12-13.pdf.pdf\n",
      "02-19-13.pdf.pdf\n",
      "02-26-13.pdf.pdf\n",
      "04-09-13.pdf.pdf\n",
      "04-23-13.pdf.pdf\n",
      "09-11-12.pdf.pdf\n",
      "10-02-12.pdf.pdf\n",
      "10-16-12.pdf.pdf\n",
      "10-23-12.pdf.pdf\n",
      "10-30-12.pdf.pdf\n",
      "11-06-12.pdf.pdf\n",
      "11-13-12.pdf.pdf\n",
      "11-27-12.pdf.pdf\n",
      "12-04-12.pdf.pdf\n",
      "12-11-12.pdf.pdf\n",
      "12-18-12.pdf.pdf\n"
     ]
    }
   ],
   "source": [
    "# path for files\n",
    "path = os.getcwd() + '/data/pdf/1213/'\n",
    "\n",
    "# file names\n",
    "filenames = os.listdir(path)\n",
    "filenames.sort()\n",
    "\n",
    "pdf = pd.DataFrame()\n",
    "df_pdf = []\n",
    "grades = ['ECE', 'PK', 'K', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12']\n",
    "\n",
    "for filename in filenames:\n",
    "    if filename.endswith('pdf'):\n",
    "        df_one = pd.DataFrame()\n",
    "        print(filename)\n",
    "\n",
    "        # read all pages from a pdf\n",
    "        # pdf returns a list of dataframes\n",
    "        # one dataframe for each page (pdf[0], pdf[1]...)\n",
    "        # does not merge files don't have projected numbers\n",
    "        pdf = tabula.read_pdf(path + filename, pages='all', multiple_tables=True, spreadsheet=True)\n",
    "\n",
    "        # merge all dataframes into one    \n",
    "        pdf = pd.concat(pdf, join='inner', axis=0)\n",
    "\n",
    "        # get columns we want, rename columns\n",
    "        pdf = pdf[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]]\n",
    "        pdf = pdf.rename({0: 'School', 1: 'ECE', 2: 'PK', 3: 'K', 4: '1', 5: '2', 6: '3', \n",
    "                          7: '4', 8: '5', 9: '6', 10: '7', 11: '8', 12: '9', 13: '10',\n",
    "                          14: '11', 15: '12'}, axis='columns')\n",
    "\n",
    "        # remove unnecessary rows (total, campus - header rows)\n",
    "        pdf = pdf[pdf['School'].str.contains('tot|campus', case=False, regex=True) != True]\n",
    "        pdf = pdf[pdf['School'].isna() != True]\n",
    "        pdf.fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "        # get dates from a filename\n",
    "        filename = filename.replace('.pdf', '').strip()\n",
    "        filename = filename.replace(' -  last day of school', '').strip()\n",
    "        if len(filename) == 10:\n",
    "            filename = datetime.datetime.strptime(filename, '%m-%d-%Y')\n",
    "        elif len(filename) == 8:\n",
    "            filename = datetime.datetime.strptime(filename, '%m-%d-%y')\n",
    "\n",
    "        pdf.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        df_one['School'] = pdf['School']\n",
    "        df_one['Date'] = filename\n",
    "        # create 14 more rows for each school (so we can have 15 grades)\n",
    "        df_one = df_one.append([df_one]*14, ignore_index=True)\n",
    "\n",
    "        # sort by school name and reset index\n",
    "        df_one = df_one.sort_values(by=['School'])\n",
    "        df_one.reset_index(inplace=True, drop=True)\n",
    "\n",
    "        for i in range(len(df_one)):\n",
    "\n",
    "            # grades\n",
    "            idx = i % 15\n",
    "            df_one.loc[i, 'Grade'] = grades[idx]\n",
    "\n",
    "\n",
    "        df_one['Enrolled'] = 0\n",
    "        for i in range(len(df_one)):\n",
    "\n",
    "            # enrollment\n",
    "            school = df_one.loc[i, 'School']\n",
    "            grade = df_one.loc[i, 'Grade']\n",
    "\n",
    "            if not pdf[pdf['School'].str.strip() == school][grade].values.size == 0:\n",
    "                df_one.loc[i, 'Enrolled'] = pdf[pdf['School'].str.strip() == school][grade].values[0]\n",
    "\n",
    "        #  change types accordingly\n",
    "        df_one['Group'] = 'Regular'\n",
    "        for i in range(len(df_one)):\n",
    "\n",
    "            # group\n",
    "            school = str(df_one.loc[i, 'School']).strip().lower()\n",
    "\n",
    "            if 'bilingual' in school:\n",
    "                df_one.loc[i, 'Group'] = 'Bilingual'\n",
    "            elif 'non‐lep dl' in school:\n",
    "                df_one.loc[i, 'Group'] = 'Non-LEP DL'\n",
    "            elif 'lep dl bil' in school:\n",
    "                df_one.loc[i, 'Group'] = 'LEP DL BIL'\n",
    "            elif 'esol' in school:\n",
    "                df_one.loc[i, 'Group'] = 'ESL'\n",
    "            elif 'esl' in school:\n",
    "                df_one.loc[i, 'Group'] = 'ESL'\n",
    "            elif 'regular' in school:\n",
    "                df_one.loc[i, 'Group'] = 'Regular'\n",
    "            elif 's/c' in school:\n",
    "                df_one.loc[i, 'Group'] = 'Self Contained'\n",
    "\n",
    "        # change school names\n",
    "        df_one['School'] = df_one['School'].str.strip().str.replace('/', ' ')\n",
    "        change_school_name(df_one)\n",
    "\n",
    "        # reset index for future use\n",
    "        df_one.reset_index(inplace=True, drop=True)\n",
    "\n",
    "        # set all schools to 'ES' (default)\n",
    "        # then change types accordingly\n",
    "        df_one['Type'] = 'ES'\n",
    "        for i in range(len(df_one)):\n",
    "            if df_one.loc[i, 'School'] in school_type.keys():\n",
    "                df_one.loc[i, 'Type'] = school_type[df_one.loc[i, 'School']]    \n",
    "\n",
    "        df_pdf.append(df_one)\n",
    "\n",
    "df_one_complete = pd.DataFrame(columns=['Date', 'School', 'Grade', 'Enrolled', 'Group', 'Type'])\n",
    "    \n",
    "for i in range(len(df_pdf)):\n",
    "    df_one_complete = df_one_complete.append(df_pdf[i], sort=False, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1_school = set(df_one_complete['School'])\n",
    "\n",
    "p1_group = set(df_one_complete['Group'])\n",
    "\n",
    "p1_type = set(df_one_complete['Type'])\n",
    "\n",
    "df_one_complete.to_csv('./pdf_1213.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01-07-2014.pdf\n",
      "01-14-2014.pdf\n",
      "01-21-2014.pdf\n",
      "01-29-2014 .pdf\n",
      "02-04-2014 .pdf\n",
      "02-11-2014.pdf\n",
      "02-18-2014.pdf\n",
      "02-25-2014.pdf\n",
      "03-04-2014.pdf\n",
      "03-18-2014.pdf\n",
      "03-25-2014.pdf\n",
      "04-01-2014.pdf\n",
      "04-08-2014.pdf\n",
      "04-15-2014 .pdf\n",
      "04-22-2014.pdf\n",
      "04-29-2014 .pdf\n",
      "05-06-2014.pdf\n",
      "05-13-2014.pdf\n",
      "05-20-2014.pdf\n",
      "05-27-2014.pdf\n"
     ]
    }
   ],
   "source": [
    "# path for files\n",
    "path = os.getcwd() + '/data/pdf/1314/'\n",
    "\n",
    "# file names\n",
    "filenames = os.listdir(path)\n",
    "filenames.sort()\n",
    "\n",
    "pdf = pd.DataFrame()\n",
    "df_pdf = []\n",
    "grades = ['ECE', 'PK', 'K', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12']\n",
    "\n",
    "for filename in filenames:\n",
    "    if filename.endswith('pdf'):\n",
    "        df_one = pd.DataFrame()\n",
    "        print(filename)\n",
    "\n",
    "        # read all pages from a pdf\n",
    "        # pdf returns a list of dataframes\n",
    "        # one dataframe for each page (pdf[0], pdf[1]...)\n",
    "        # does not merge files don't have projected numbers\n",
    "        pdf = tabula.read_pdf(path + filename, pages='all', multiple_tables=True, spreadsheet=True)\n",
    "\n",
    "        # merge all dataframes into one    \n",
    "        pdf = pd.concat(pdf, join='inner', axis=0)\n",
    "\n",
    "        # get columns we want, rename columns\n",
    "        pdf = pdf[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]]\n",
    "        pdf = pdf.rename({0: 'School', 1: 'ECE', 2: 'PK', 3: 'K', 4: '1', 5: '2', 6: '3', \n",
    "                          7: '4', 8: '5', 9: '6', 10: '7', 11: '8', 12: '9', 13: '10',\n",
    "                          14: '11', 15: '12'}, axis='columns')\n",
    "\n",
    "        # remove unnecessary rows (total, campus - header rows)\n",
    "        pdf = pdf[pdf['School'].str.contains('tot|campus', case=False, regex=True) != True]\n",
    "        pdf = pdf[pdf['School'].isna() != True]\n",
    "        pdf.fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "        # get dates from a filename\n",
    "        filename = filename.replace('.pdf', '').strip()\n",
    "        filename = filename.replace(' -  last day of school', '').strip()\n",
    "        if len(filename) == 10:\n",
    "            filename = datetime.datetime.strptime(filename, '%m-%d-%Y')\n",
    "        elif len(filename) == 8:\n",
    "            filename = datetime.datetime.strptime(filename, '%m-%d-%y')\n",
    "\n",
    "        pdf.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        df_one['School'] = pdf['School']\n",
    "        df_one['Date'] = filename\n",
    "        # create 14 more rows for each school (so we can have 15 grades)\n",
    "        df_one = df_one.append([df_one]*14, ignore_index=True)\n",
    "\n",
    "        # sort by school name and reset index\n",
    "        df_one = df_one.sort_values(by=['School'])\n",
    "        df_one.reset_index(inplace=True, drop=True)\n",
    "\n",
    "        for i in range(len(df_one)):\n",
    "\n",
    "            # grades\n",
    "            idx = i % 15\n",
    "            df_one.loc[i, 'Grade'] = grades[idx]\n",
    "\n",
    "\n",
    "        df_one['Enrolled'] = 0\n",
    "        for i in range(len(df_one)):\n",
    "\n",
    "            # enrollment\n",
    "            school = df_one.loc[i, 'School']\n",
    "            grade = df_one.loc[i, 'Grade']\n",
    "\n",
    "            if not pdf[pdf['School'].str.strip() == school][grade].values.size == 0:\n",
    "                df_one.loc[i, 'Enrolled'] = pdf[pdf['School'].str.strip() == school][grade].values[0]\n",
    "\n",
    "        #  change types accordingly\n",
    "        df_one['Group'] = 'Regular'\n",
    "        for i in range(len(df_one)):\n",
    "\n",
    "            # group\n",
    "            school = str(df_one.loc[i, 'School']).strip().lower()\n",
    "\n",
    "            if 'bilingual' in school:\n",
    "                df_one.loc[i, 'Group'] = 'Bilingual'\n",
    "            elif 'non‐lep dl' in school:\n",
    "                df_one.loc[i, 'Group'] = 'Non-LEP DL'\n",
    "            elif 'lep dl bil' in school:\n",
    "                df_one.loc[i, 'Group'] = 'LEP DL BIL'\n",
    "            elif 'esol' in school:\n",
    "                df_one.loc[i, 'Group'] = 'ESL'\n",
    "            elif 'esl' in school:\n",
    "                df_one.loc[i, 'Group'] = 'ESL'\n",
    "            elif 'regular' in school:\n",
    "                df_one.loc[i, 'Group'] = 'Regular'\n",
    "            elif 's/c' in school:\n",
    "                df_one.loc[i, 'Group'] = 'Self Contained'\n",
    "\n",
    "        # change school names\n",
    "        df_one['School'] = df_one['School'].str.strip().str.replace('/', ' ')\n",
    "        change_school_name(df_one)\n",
    "\n",
    "        # reset index for future use\n",
    "        df_one.reset_index(inplace=True, drop=True)\n",
    "\n",
    "        # set all schools to 'ES' (default)\n",
    "        # then change types accordingly\n",
    "        df_one['Type'] = 'ES'\n",
    "        for i in range(len(df_one)):\n",
    "            if df_one.loc[i, 'School'] in school_type.keys():\n",
    "                df_one.loc[i, 'Type'] = school_type[df_one.loc[i, 'School']]    \n",
    "\n",
    "        df_pdf.append(df_one)\n",
    "\n",
    "df_two_complete = pd.DataFrame(columns=['Date', 'School', 'Grade', 'Enrolled', 'Group', 'Type'])\n",
    "    \n",
    "for i in range(len(df_pdf)):\n",
    "    df_two_complete = df_two_complete.append(df_pdf[i], sort=False, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2_school = set(df_two_complete['School'])\n",
    "\n",
    "p2_group = set(df_two_complete['Group'])\n",
    "\n",
    "p2_type = set(df_two_complete['Type'])\n",
    "\n",
    "df_two_complete.to_csv('./pdf_1314.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01-06-2015.pdf\n",
      "01-13-2015.pdf\n",
      "01-20-2015.pdf\n",
      "01-27-2015.pdf\n",
      "02-03-2015.pdf\n",
      "02-10-2015.pdf\n",
      "02-17-15.pdf\n",
      "03-03-2015.pdf\n",
      "03-10-2015.pdf\n",
      "03-24-2015.pdf\n",
      "03-31-2015.pdf\n",
      "04-07-2015.pdf\n",
      "04-14-2015.pdf\n",
      "04-21-2015.pdf\n",
      "04-28-2015.pdf\n",
      "05-05-2015.pdf\n",
      "05-12-2015.pdf\n",
      "05-19-2015.pdf\n",
      "05-26-2015.pdf\n",
      "08-26-14.pdf\n",
      "09-02-14.pdf\n",
      "09-09-2014.pdf\n",
      "09-16-2014.pdf\n",
      "09-23-2014.pdf\n",
      "09-30-2014.pdf\n",
      "10-08-14.pdf\n",
      "10-15-14.pdf\n",
      "10-22-14.pdf\n",
      "10-28-14.pdf\n",
      "11-04-14.pdf\n",
      "11-11-14.pdf\n",
      "11-18-14.pdf\n",
      "11-25-14.pdf\n",
      "12-02-14.pdf\n",
      "12-09-14.pdf\n",
      "12-16-14.pdf\n"
     ]
    }
   ],
   "source": [
    "# path for files\n",
    "path = os.getcwd() + '/data/pdf/1415/'\n",
    "\n",
    "# file names\n",
    "filenames = os.listdir(path)\n",
    "filenames.sort()\n",
    "\n",
    "pdf = pd.DataFrame()\n",
    "df_pdf = []\n",
    "grades = ['ECE', 'PK', 'K', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12']\n",
    "\n",
    "for filename in filenames:\n",
    "    if filename.endswith('pdf'):\n",
    "        df_one = pd.DataFrame()\n",
    "        print(filename)\n",
    "\n",
    "        # read all pages from a pdf\n",
    "        # pdf returns a list of dataframes\n",
    "        # one dataframe for each page (pdf[0], pdf[1]...)\n",
    "        # does not merge files don't have projected numbers\n",
    "        pdf = tabula.read_pdf(path + filename, pages='all', multiple_tables=True, spreadsheet=True)\n",
    "\n",
    "        # merge all dataframes into one    \n",
    "        pdf = pd.concat(pdf, join='inner', axis=0)\n",
    "\n",
    "        # get columns we want, rename columns\n",
    "        pdf = pdf[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]]\n",
    "        pdf = pdf.rename({0: 'School', 1: 'ECE', 2: 'PK', 3: 'K', 4: '1', 5: '2', 6: '3', \n",
    "                          7: '4', 8: '5', 9: '6', 10: '7', 11: '8', 12: '9', 13: '10',\n",
    "                          14: '11', 15: '12'}, axis='columns')\n",
    "\n",
    "        # remove unnecessary rows (total, campus - header rows)\n",
    "        pdf = pdf[pdf['School'].str.contains('tot|campus', case=False, regex=True) != True]\n",
    "        pdf = pdf[pdf['School'].isna() != True]\n",
    "        pdf.fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "        # get dates from a filename\n",
    "        filename = filename.replace('.pdf', '').strip()\n",
    "        filename = filename.replace(' -  last day of school', '').strip()\n",
    "        if len(filename) == 10:\n",
    "            filename = datetime.datetime.strptime(filename, '%m-%d-%Y')\n",
    "        elif len(filename) == 8:\n",
    "            filename = datetime.datetime.strptime(filename, '%m-%d-%y')\n",
    "\n",
    "        pdf.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        df_one['School'] = pdf['School']\n",
    "        df_one['Date'] = filename\n",
    "        # create 14 more rows for each school (so we can have 15 grades)\n",
    "        df_one = df_one.append([df_one]*14, ignore_index=True)\n",
    "\n",
    "        # sort by school name and reset index\n",
    "        df_one = df_one.sort_values(by=['School'])\n",
    "        df_one.reset_index(inplace=True, drop=True)\n",
    "\n",
    "        for i in range(len(df_one)):\n",
    "\n",
    "            # grades\n",
    "            idx = i % 15\n",
    "            df_one.loc[i, 'Grade'] = grades[idx]\n",
    "\n",
    "\n",
    "        df_one['Enrolled'] = 0\n",
    "        for i in range(len(df_one)):\n",
    "\n",
    "            # enrollment\n",
    "            school = df_one.loc[i, 'School']\n",
    "            grade = df_one.loc[i, 'Grade']\n",
    "\n",
    "            if not pdf[pdf['School'].str.strip() == school][grade].values.size == 0:\n",
    "                df_one.loc[i, 'Enrolled'] = pdf[pdf['School'].str.strip() == school][grade].values[0]\n",
    "\n",
    "        #  change types accordingly\n",
    "        df_one['Group'] = 'Regular'\n",
    "        for i in range(len(df_one)):\n",
    "\n",
    "            # group\n",
    "            school = str(df_one.loc[i, 'School']).strip().lower()\n",
    "\n",
    "            if 'bilingual' in school:\n",
    "                df_one.loc[i, 'Group'] = 'Bilingual'\n",
    "            elif 'non‐lep dl' in school:\n",
    "                df_one.loc[i, 'Group'] = 'Non-LEP DL'\n",
    "            elif 'lep dl bil' in school:\n",
    "                df_one.loc[i, 'Group'] = 'LEP DL BIL'\n",
    "            elif 'esol' in school:\n",
    "                df_one.loc[i, 'Group'] = 'ESL'\n",
    "            elif 'esl' in school:\n",
    "                df_one.loc[i, 'Group'] = 'ESL'\n",
    "            elif 'regular' in school:\n",
    "                df_one.loc[i, 'Group'] = 'Regular'\n",
    "            elif 's/c' in school:\n",
    "                df_one.loc[i, 'Group'] = 'Self Contained'\n",
    "            elif 'self contained' in school:\n",
    "                df_one.loc[i, 'Group'] = 'Self Contained'\n",
    "\n",
    "        # change school names\n",
    "        df_one['School'] = df_one['School'].str.strip().str.replace('/', ' ')\n",
    "        df_one['School'] = df_one['School'].str.strip().str.replace('  ', ' ')\n",
    "        change_school_name(df_one)\n",
    "\n",
    "        # reset index for future use\n",
    "        df_one.reset_index(inplace=True, drop=True)\n",
    "\n",
    "        # set all schools to 'ES' (default)\n",
    "        # then change types accordingly\n",
    "        df_one['Type'] = 'ES'\n",
    "        for i in range(len(df_one)):\n",
    "            if df_one.loc[i, 'School'] in school_type.keys():\n",
    "                df_one.loc[i, 'Type'] = school_type[df_one.loc[i, 'School']]    \n",
    "\n",
    "        df_pdf.append(df_one)\n",
    "\n",
    "df_three_complete = pd.DataFrame(columns=['Date', 'School', 'Grade', 'Enrolled', 'Group', 'Type'])\n",
    "    \n",
    "for i in range(len(df_pdf)):\n",
    "    df_three_complete = df_three_complete.append(df_pdf[i], sort=False, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "p3_school = set(df_three_complete['School'])\n",
    "\n",
    "p3_group = set(df_three_complete['Group'])\n",
    "\n",
    "p3_type = set(df_three_complete['Type'])\n",
    "\n",
    "df_three_complete.to_csv('./pdf_1415.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01-05-2016.pdf\n",
      "01-12-2016.pdf\n",
      "01-19-2016.pdf\n",
      "01-26-2016.pdf\n",
      "02-02-2016.pdf\n",
      "02-09-2016.pdf\n",
      "02-16-2016.pdf\n",
      "02-23-2016.pdf\n",
      "03-01-2016.pdf\n",
      "03-08-2016.pdf\n",
      "03-22-2016.pdf\n",
      "03-29-2016.pdf\n",
      "04-06-2016.pdf\n",
      "04-12-2016.pdf\n",
      "04-19-2016.pdf\n",
      "04-26-2016.pdf\n",
      "05-03-2016.pdf\n",
      "05-10-2016.pdf\n",
      "05-17-2016.pdf\n",
      "05-24-2016.pdf\n",
      "06-02-2016 -  last day of school.pdf\n",
      "09-22-2015.pdf\n",
      "10-27-2015.pdf\n",
      "11-03-2015.pdf\n",
      "11-10-2015.pdf\n",
      "11-17-2015.pdf\n",
      "12-01-2015.pdf\n",
      "12-08-2015.pdf\n",
      "12-15-2015.pdf\n"
     ]
    }
   ],
   "source": [
    "# path for files\n",
    "path = os.getcwd() + '/data/pdf/1516/'\n",
    "\n",
    "# file names\n",
    "filenames = os.listdir(path)\n",
    "filenames.sort()\n",
    "\n",
    "pdf = pd.DataFrame()\n",
    "df_pdf = []\n",
    "grades = ['ECE', 'PK', 'K', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12']\n",
    "\n",
    "for filename in filenames:\n",
    "    if filename.endswith('pdf'):\n",
    "        df_one = pd.DataFrame()\n",
    "        print(filename)\n",
    "\n",
    "        # read all pages from a pdf\n",
    "        # pdf returns a list of dataframes\n",
    "        # one dataframe for each page (pdf[0], pdf[1]...)\n",
    "        # does not merge files don't have projected numbers\n",
    "        pdf = tabula.read_pdf(path + filename, pages='all', multiple_tables=True, spreadsheet=True)\n",
    "\n",
    "        # merge all dataframes into one    \n",
    "        pdf = pd.concat(pdf, join='inner', axis=0)\n",
    "\n",
    "        # get columns we want, rename columns\n",
    "        pdf = pdf[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]]\n",
    "        pdf = pdf.rename({0: 'School', 1: 'ECE', 2: 'PK', 3: 'K', 4: '1', 5: '2', 6: '3', \n",
    "                          7: '4', 8: '5', 9: '6', 10: '7', 11: '8', 12: '9', 13: '10',\n",
    "                          14: '11', 15: '12'}, axis='columns')\n",
    "\n",
    "        # remove unnecessary rows (total, campus - header rows)\n",
    "        pdf = pdf[pdf['School'].str.contains('tot|campus', case=False, regex=True) != True]\n",
    "        pdf = pdf[pdf['School'].isna() != True]\n",
    "        pdf.fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "        # get dates from a filename\n",
    "        filename = filename.replace('.pdf', '').strip()\n",
    "        filename = filename.replace(' -  last day of school', '').strip()\n",
    "        if len(filename) == 10:\n",
    "            filename = datetime.datetime.strptime(filename, '%m-%d-%Y')\n",
    "        elif len(filename) == 8:\n",
    "            filename = datetime.datetime.strptime(filename, '%m-%d-%y')\n",
    "\n",
    "        pdf.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        df_one['School'] = pdf['School']\n",
    "        df_one['Date'] = filename\n",
    "        # create 14 more rows for each school (so we can have 15 grades)\n",
    "        df_one = df_one.append([df_one]*14, ignore_index=True)\n",
    "\n",
    "        # sort by school name and reset index\n",
    "        df_one = df_one.sort_values(by=['School'])\n",
    "        df_one.reset_index(inplace=True, drop=True)\n",
    "\n",
    "        for i in range(len(df_one)):\n",
    "\n",
    "            # grades\n",
    "            idx = i % 15\n",
    "            df_one.loc[i, 'Grade'] = grades[idx]\n",
    "\n",
    "\n",
    "        df_one['Enrolled'] = 0\n",
    "        for i in range(len(df_one)):\n",
    "\n",
    "            # enrollment\n",
    "            school = df_one.loc[i, 'School']\n",
    "            grade = df_one.loc[i, 'Grade']\n",
    "\n",
    "            if not pdf[pdf['School'].str.strip() == school][grade].values.size == 0:\n",
    "                df_one.loc[i, 'Enrolled'] = pdf[pdf['School'].str.strip() == school][grade].values[0]\n",
    "\n",
    "        #  change types accordingly\n",
    "        df_one['Group'] = 'Regular'\n",
    "        for i in range(len(df_one)):\n",
    "\n",
    "            # group\n",
    "            school = str(df_one.loc[i, 'School']).strip().lower()\n",
    "            if 'bilingual' in school:\n",
    "                df_one.loc[i, 'Group'] = 'Bilingual'\n",
    "            elif 'non-lep dl' in school:\n",
    "                df_one.loc[i, 'Group'] = 'Non-LEP DL'\n",
    "            elif 'lep dl bil' in school:\n",
    "                df_one.loc[i, 'Group'] = 'LEP DL BIL'\n",
    "            elif 'esol' in school:\n",
    "                df_one.loc[i, 'Group'] = 'ESL'\n",
    "            elif 'esl' in school:\n",
    "                df_one.loc[i, 'Group'] = 'ESL'\n",
    "            elif 'regular' in school:\n",
    "                df_one.loc[i, 'Group'] = 'Regular'\n",
    "            elif 's/c' in school:\n",
    "                df_one.loc[i, 'Group'] = 'Self Contained'\n",
    "            elif 'self contained' in school:\n",
    "                df_one.loc[i, 'Group'] = 'Self Contained'\n",
    "\n",
    "        # change school names\n",
    "        df_one['School'] = df_one['School'].str.strip().str.replace('/', ' ')\n",
    "        df_one['School'] = df_one['School'].str.strip().str.replace('  ', ' ')\n",
    "        change_school_name(df_one)\n",
    "\n",
    "        # reset index for future use\n",
    "        df_one.reset_index(inplace=True, drop=True)\n",
    "\n",
    "        # set all schools to 'ES' (default)\n",
    "        # then change types accordingly\n",
    "        df_one['Type'] = 'ES'\n",
    "        for i in range(len(df_one)):\n",
    "            if df_one.loc[i, 'School'] in school_type.keys():\n",
    "                df_one.loc[i, 'Type'] = school_type[df_one.loc[i, 'School']]    \n",
    "\n",
    "        df_pdf.append(df_one)\n",
    "\n",
    "df_four_complete = pd.DataFrame(columns=['Date', 'School', 'Grade', 'Enrolled', 'Group', 'Type'])\n",
    "    \n",
    "for i in range(len(df_pdf)):\n",
    "    df_four_complete = df_four_complete.append(df_pdf[i], sort=False, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "p4_school = set(df_four_complete['School'])\n",
    "\n",
    "p4_group = set(df_four_complete['Group'])\n",
    "\n",
    "p4_type = set(df_four_complete['Type'])\n",
    "\n",
    "df_four_complete.to_csv('./pdf_1516.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_one_complete.append([df_two_complete, df_three_complete, df_four_complete], sort=False)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 206040 entries, 0 to 206039\n",
      "Data columns (total 6 columns):\n",
      "Date        206040 non-null datetime64[ns]\n",
      "School      206040 non-null object\n",
      "Grade       206040 non-null object\n",
      "Enrolled    206040 non-null int64\n",
      "Group       206040 non-null object\n",
      "Type        206040 non-null object\n",
      "dtypes: datetime64[ns](1), int64(1), object(4)\n",
      "memory usage: 9.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Enrolled'] = df['Enrolled'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./pdf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Bilingual', 'ESL', 'Non-LEP DL', 'Regular', 'Self Contained'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df['Group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02-24-2015.pdf\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'[ 2  3  4  5  6  7  8  9 10 11 12 13 14 15] not in index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-74f9da296e6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# get columns we want, rename columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mpdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m13\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m14\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         pdf = pdf.rename({0: 'School', 1: 'ECE', 2: 'PK', 3: 'K', 4: '1', 5: '2', 6: '3', \n\u001b[1;32m     29\u001b[0m                           \u001b[0;36m7\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'4'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'6'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'7'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'8'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'9'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m13\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'10'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2680\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2681\u001b[0m             \u001b[0;31m# either boolean or fancy integer index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2682\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2683\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2684\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2724\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2725\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2726\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2727\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter)\u001b[0m\n\u001b[1;32m   1325\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m                     raise KeyError('{mask} not in index'\n\u001b[0;32m-> 1327\u001b[0;31m                                    .format(mask=objarr[mask]))\n\u001b[0m\u001b[1;32m   1328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values_from_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '[ 2  3  4  5  6  7  8  9 10 11 12 13 14 15] not in index'"
     ]
    }
   ],
   "source": [
    "# path for files\n",
    "path = os.getcwd() + '/data/pdf/etc/'\n",
    "\n",
    "# file names\n",
    "filenames = os.listdir(path)\n",
    "filenames.sort()\n",
    "\n",
    "pdf = pd.DataFrame()\n",
    "df_pdf = []\n",
    "grades = ['ECE', 'PK', 'K', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12']\n",
    "\n",
    "for filename in filenames:\n",
    "    if filename.endswith('pdf'):\n",
    "        df_one = pd.DataFrame()\n",
    "        print(filename)\n",
    "\n",
    "        # read all pages from a pdf\n",
    "        # pdf returns a list of dataframes\n",
    "        # one dataframe for each page (pdf[0], pdf[1]...)\n",
    "        # does not merge files don't have projected numbers\n",
    "        pdf = tabula.read_pdf(path + filename, pages='all', multiple_tables=True, spreadsheet=True)\n",
    "\n",
    "        # merge all dataframes into one    \n",
    "        pdf = pd.concat(pdf, join='inner', axis=0)\n",
    "\n",
    "        # get columns we want, rename columns\n",
    "        pdf = pdf[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]]\n",
    "        pdf = pdf.rename({0: 'School', 1: 'ECE', 2: 'PK', 3: 'K', 4: '1', 5: '2', 6: '3', \n",
    "                          7: '4', 8: '5', 9: '6', 10: '7', 11: '8', 12: '9', 13: '10',\n",
    "                          14: '11', 15: '12'}, axis='columns')\n",
    "\n",
    "        # remove unnecessary rows (total, campus - header rows)\n",
    "        pdf = pdf[pdf['School'].str.contains('tot|campus', case=False, regex=True) != True]\n",
    "        pdf = pdf[pdf['School'].isna() != True]\n",
    "        pdf.fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "        # get dates from a filename\n",
    "        filename = filename.replace('.pdf', '').strip()\n",
    "        filename = filename.replace(' -  last day of school', '').strip()\n",
    "        if len(filename) == 10:\n",
    "            filename = datetime.datetime.strptime(filename, '%m-%d-%Y')\n",
    "        elif len(filename) == 8:\n",
    "            filename = datetime.datetime.strptime(filename, '%m-%d-%y')\n",
    "\n",
    "        pdf.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        df_one['School'] = pdf['School']\n",
    "        df_one['Date'] = filename\n",
    "        # create 14 more rows for each school (so we can have 15 grades)\n",
    "        df_one = df_one.append([df_one]*14, ignore_index=True)\n",
    "\n",
    "        # sort by school name and reset index\n",
    "        df_one = df_one.sort_values(by=['School'])\n",
    "        df_one.reset_index(inplace=True, drop=True)\n",
    "\n",
    "        for i in range(len(df_one)):\n",
    "\n",
    "            # grades\n",
    "            idx = i % 15\n",
    "            df_one.loc[i, 'Grade'] = grades[idx]\n",
    "\n",
    "\n",
    "        df_one['Enrolled'] = 0\n",
    "        for i in range(len(df_one)):\n",
    "\n",
    "            # enrollment\n",
    "            school = df_one.loc[i, 'School']\n",
    "            grade = df_one.loc[i, 'Grade']\n",
    "\n",
    "            if not pdf[pdf['School'].str.strip() == school][grade].values.size == 0:\n",
    "                df_one.loc[i, 'Enrolled'] = pdf[pdf['School'].str.strip() == school][grade].values[0]\n",
    "\n",
    "        #  change types accordingly\n",
    "        df_one['Group'] = 'Regular'\n",
    "        for i in range(len(df_one)):\n",
    "\n",
    "            # group\n",
    "            school = str(df_one.loc[i, 'School']).strip().lower()\n",
    "            if 'bilingual' in school:\n",
    "                df_one.loc[i, 'Group'] = 'Bilingual'\n",
    "            elif 'non-lep dl' in school:\n",
    "                df_one.loc[i, 'Group'] = 'Non-LEP DL'\n",
    "            elif 'lep dl bil' in school:\n",
    "                df_one.loc[i, 'Group'] = 'LEP DL BIL'\n",
    "            elif 'esol' in school:\n",
    "                df_one.loc[i, 'Group'] = 'ESL'\n",
    "            elif 'esl' in school:\n",
    "                df_one.loc[i, 'Group'] = 'ESL'\n",
    "            elif 'regular' in school:\n",
    "                df_one.loc[i, 'Group'] = 'Regular'\n",
    "            elif 's/c' in school:\n",
    "                df_one.loc[i, 'Group'] = 'Self Contained'\n",
    "            elif 'self contained' in school:\n",
    "                df_one.loc[i, 'Group'] = 'Self Contained'\n",
    "\n",
    "        # change school names\n",
    "        df_one['School'] = df_one['School'].str.strip().str.replace('/', ' ')\n",
    "        df_one['School'] = df_one['School'].str.strip().str.replace('  ', ' ')\n",
    "        change_school_name(df_one)\n",
    "\n",
    "        # reset index for future use\n",
    "        df_one.reset_index(inplace=True, drop=True)\n",
    "\n",
    "        # set all schools to 'ES' (default)\n",
    "        # then change types accordingly\n",
    "        df_one['Type'] = 'ES'\n",
    "        for i in range(len(df_one)):\n",
    "            if df_one.loc[i, 'School'] in school_type.keys():\n",
    "                df_one.loc[i, 'Type'] = school_type[df_one.loc[i, 'School']]    \n",
    "\n",
    "        df_pdf.append(df_one)\n",
    "\n",
    "df_one_complete = pd.DataFrame(columns=['Date', 'School', 'Grade', 'Enrolled', 'Group', 'Type'])\n",
    "    \n",
    "for i in range(len(df_pdf)):\n",
    "    df_one_complete = df_one_complete.append(df_pdf[i], sort=False, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'JJAEP LOTT'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1_school - p2_school"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
